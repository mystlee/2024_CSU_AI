{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPVL5JzUpCbkw6SZamel4yv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mystlee/2024_CSU_AI/blob/main/chapter5/transfer_learning_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 필요한 라이브러리 설치\n",
        "\n",
        "먼저 필요한 라이브러리를 설치\n",
        "- torch: pytorch 라이브러리\n",
        "- torchvision: 영상처리와 관련된 pytorch 라이브러리"
      ],
      "metadata": {
        "id": "cTpeDVPStJSr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nhNsFwYtECv",
        "outputId": "786666ee-7e4b-4e53-f190-ab1b14b4cd83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 데이터셋 준비   \n",
        "CIFAR-10 데이터셋을 사용하여 모델을 학습   \n",
        "데이터 전처리를 위해 transforms를 정의, 데이터셋을 로드   \n",
        "- transform은 transformer가 아니라 데이터를 변환\n",
        "- torch에서 제공하는 transform을 이용해서 데이터 증강 (augmentation)도 가능함!\n",
        "\n",
        "다양한 데이터 증강 기법은 아래 사이트 참고!   \n",
        "https://pytorch.org/vision/0.9/transforms.html   \n",
        "\n"
      ],
      "metadata": {
        "id": "1ZFz9DTktJ66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# 데이터 전처리\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # ResNet의 입력 크기에 맞게 조정\n",
        "    transforms.RandomHorizontalFlip(),  # 데이터 증강: 좌우 반전\n",
        "    transforms.ToTensor(), # pytorch 포맷에 맞게 변환\n",
        "    transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
        "                         std = [0.229, 0.224, 0.225]), # 입력 데이터 정규화\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
        "                         std = [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# 훈련 및 검증 데이터셋 로드\n",
        "train_dataset = datasets.CIFAR10(root = './data', train = True, download = True, transform = transform_train)\n",
        "val_dataset = datasets.CIFAR10(root = './data', train = False, download = True, transform = transform_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NypnWrbtL0D",
        "outputId": "2cd17a06-cf22-495a-cfc2-cca850423083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 13.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 데이터로더 준비   \n",
        "훈련 및 검증 데이터로더를 생성하고, 배치 크기와 셔플 여부를 설정"
      ],
      "metadata": {
        "id": "ukNy7eh3tMGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 4)\n",
        "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False, num_workers = 4)\n"
      ],
      "metadata": {
        "id": "paQhryZ6tMdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 모델 로드 및 수정   \n",
        "torchvision의 사전 학습된 ResNet-50 모델을 로드   \n",
        "마지막 완전 연결층(fc layer)을 CIFAR-10의 클래스 수에 맞게 수정   \n",
        "https://pytorch.org/vision/stable/models.html#general-information-on-pre-trained-weights"
      ],
      "metadata": {
        "id": "MJAPMjMJtMvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "# model = models.resnet50(pretrained = True)\n",
        "model = torch.hub.load(\"pytorch/vision\", \"resnet50\", weights = \"IMAGENET1K_V2\")\n",
        "# model = models.resnet50(pretrained = False)\n",
        "\n",
        "# 마지막 완전 연결층 수정\n",
        "num_ftrs = model.fc.in_features\n",
        "num_classes = 10  # CIFAR-10의 클래스 수\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "# 모델을 GPU로 이동 (가능한 경우)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV1rxwLTtNG-",
        "outputId": "8f32b0f6-e571-4dea-936a-8e854593d3ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 227MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 손실 함수 및 옵티마이저 설정   \n",
        "손실 함수로 교차 엔트로피 손실(CrossEntropyLoss)을 사용   \n",
        "옵티마이저로 Adam을 설정 (파인튜닝 시에는 보통 학습률을 낮게 설정!)"
      ],
      "metadata": {
        "id": "GKZUM5-CtNVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 1e-4)"
      ],
      "metadata": {
        "id": "F3CN-g-AtNjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 학습 및 검증 루프 정의   \n",
        "훈련과 검증을 위한 함수를 정의   \n",
        "각 에포크(epoch)마다 모델을 학습시키고 검증 데이터를 통해 성능을 평가"
      ],
      "metadata": {
        "id": "O0FiUXq2tNx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, dataloader, criterion, optimizer, device, log_interval=1000):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    step = 0  # 현재 에포크 내 스텝 수\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        step += 1\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # 전체 스텝 수는 외부에서 관리\n",
        "        if (step % log_interval == 0):\n",
        "            current_loss = running_loss / total\n",
        "            current_acc = correct / total\n",
        "            print(f'Step {step}: Train Loss: {current_loss:.4f} | Train Acc: {current_acc:.4f}')\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "TRbCv0MptOC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. 모델 학습\n",
        "정의한 함수를 사용하여 모델을 여러 에포크 동안 학습시킴   \n",
        "각 에포크마다 훈련 손실 및 정확도, 검증 손실 및 정확도를 출력"
      ],
      "metadata": {
        "id": "tBNjncWbxlgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "num_epochs = 10\n",
        "log_interval = 100  # 1000 스텝마다 로그 출력\n",
        "\n",
        "best_val_acc = 0.0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "patience = 5\n",
        "trigger_times = 0\n",
        "\n",
        "# 전체 스텝 수를 추적하기 위해 카운터 설정\n",
        "global_step = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "    print('-' * 30)\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for step, (inputs, labels) in enumerate(train_loader, 1):\n",
        "        global_step += 1\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        if global_step % log_interval == 0:\n",
        "            current_loss = running_loss / total\n",
        "            current_acc = correct / total\n",
        "            print(f'Step {global_step}: Train Loss: {current_loss:.4f} | Train Acc: {current_acc:.4f}')\n",
        "\n",
        "    # 에포크 종료 후 전체 에포크 손실 및 정확도 계산\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_acc = correct / len(train_loader.dataset)\n",
        "\n",
        "    # 검증 단계\n",
        "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "    print(f'Epoch {epoch + 1} Summary')\n",
        "    print(f'Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc:.4f}')\n",
        "    print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n",
        "    print('-' * 30)\n",
        "\n",
        "    # 조기 종료 및 최적 모델 저장\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        trigger_times = 0\n",
        "    else:\n",
        "        trigger_times += 1\n",
        "        if trigger_times >= patience:\n",
        "            print('Early stopping!')\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY8UtWB0xmTz",
        "outputId": "adede378-83bb-4553-d890-9c09bb19a126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "------------------------------\n",
            "Step 100: Train Loss: 1.3369 | Train Acc: 0.6162\n",
            "Step 200: Train Loss: 0.9005 | Train Acc: 0.7356\n",
            "Step 300: Train Loss: 0.7239 | Train Acc: 0.7843\n",
            "Step 400: Train Loss: 0.6254 | Train Acc: 0.8113\n",
            "Step 500: Train Loss: 0.5572 | Train Acc: 0.8310\n",
            "Step 600: Train Loss: 0.5109 | Train Acc: 0.8438\n",
            "Step 700: Train Loss: 0.4752 | Train Acc: 0.8538\n",
            "Step 800: Train Loss: 0.4455 | Train Acc: 0.8621\n",
            "Step 900: Train Loss: 0.4227 | Train Acc: 0.8679\n",
            "Step 1000: Train Loss: 0.4032 | Train Acc: 0.8738\n",
            "Step 1100: Train Loss: 0.3861 | Train Acc: 0.8784\n",
            "Step 1200: Train Loss: 0.3704 | Train Acc: 0.8833\n",
            "Step 1300: Train Loss: 0.3571 | Train Acc: 0.8872\n",
            "Step 1400: Train Loss: 0.3457 | Train Acc: 0.8906\n",
            "Step 1500: Train Loss: 0.3359 | Train Acc: 0.8936\n",
            "Epoch 1 Summary\n",
            "Train Loss: 0.3305 | Train Acc: 0.8953\n",
            "Val Loss: 0.1360 | Val Acc: 0.9544\n",
            "------------------------------\n",
            "Epoch 2/10\n",
            "------------------------------\n",
            "Step 1600: Train Loss: 0.1269 | Train Acc: 0.9603\n",
            "Step 1700: Train Loss: 0.1225 | Train Acc: 0.9619\n",
            "Step 1800: Train Loss: 0.1223 | Train Acc: 0.9614\n",
            "Step 1900: Train Loss: 0.1252 | Train Acc: 0.9603\n",
            "Step 2000: Train Loss: 0.1263 | Train Acc: 0.9596\n",
            "Step 2100: Train Loss: 0.1256 | Train Acc: 0.9594\n",
            "Step 2200: Train Loss: 0.1253 | Train Acc: 0.9593\n",
            "Step 2300: Train Loss: 0.1280 | Train Acc: 0.9581\n",
            "Step 2400: Train Loss: 0.1282 | Train Acc: 0.9579\n",
            "Step 2500: Train Loss: 0.1270 | Train Acc: 0.9580\n",
            "Step 2600: Train Loss: 0.1281 | Train Acc: 0.9575\n",
            "Step 2700: Train Loss: 0.1299 | Train Acc: 0.9570\n",
            "Step 2800: Train Loss: 0.1300 | Train Acc: 0.9570\n",
            "Step 2900: Train Loss: 0.1284 | Train Acc: 0.9576\n",
            "Step 3000: Train Loss: 0.1283 | Train Acc: 0.9577\n",
            "Step 3100: Train Loss: 0.1274 | Train Acc: 0.9578\n",
            "Epoch 2 Summary\n",
            "Train Loss: 0.1271 | Train Acc: 0.9578\n",
            "Val Loss: 0.1343 | Val Acc: 0.9547\n",
            "------------------------------\n",
            "Epoch 3/10\n",
            "------------------------------\n",
            "Step 3200: Train Loss: 0.0731 | Train Acc: 0.9768\n",
            "Step 3300: Train Loss: 0.0740 | Train Acc: 0.9761\n",
            "Step 3400: Train Loss: 0.0746 | Train Acc: 0.9746\n",
            "Step 3500: Train Loss: 0.0719 | Train Acc: 0.9763\n",
            "Step 3600: Train Loss: 0.0733 | Train Acc: 0.9761\n",
            "Step 3700: Train Loss: 0.0739 | Train Acc: 0.9758\n",
            "Step 3800: Train Loss: 0.0764 | Train Acc: 0.9752\n",
            "Step 3900: Train Loss: 0.0771 | Train Acc: 0.9750\n",
            "Step 4000: Train Loss: 0.0773 | Train Acc: 0.9754\n",
            "Step 4100: Train Loss: 0.0783 | Train Acc: 0.9749\n",
            "Step 4200: Train Loss: 0.0796 | Train Acc: 0.9742\n",
            "Step 4300: Train Loss: 0.0806 | Train Acc: 0.9734\n",
            "Step 4400: Train Loss: 0.0803 | Train Acc: 0.9736\n",
            "Step 4500: Train Loss: 0.0812 | Train Acc: 0.9732\n",
            "Step 4600: Train Loss: 0.0814 | Train Acc: 0.9732\n",
            "Epoch 3 Summary\n",
            "Train Loss: 0.0817 | Train Acc: 0.9727\n",
            "Val Loss: 0.1472 | Val Acc: 0.9547\n",
            "------------------------------\n",
            "Epoch 4/10\n",
            "------------------------------\n",
            "Step 4700: Train Loss: 0.0712 | Train Acc: 0.9773\n",
            "Step 4800: Train Loss: 0.0692 | Train Acc: 0.9766\n",
            "Step 4900: Train Loss: 0.0649 | Train Acc: 0.9782\n",
            "Step 5000: Train Loss: 0.0612 | Train Acc: 0.9789\n",
            "Step 5100: Train Loss: 0.0620 | Train Acc: 0.9792\n",
            "Step 5200: Train Loss: 0.0628 | Train Acc: 0.9793\n",
            "Step 5300: Train Loss: 0.0607 | Train Acc: 0.9803\n",
            "Step 5400: Train Loss: 0.0618 | Train Acc: 0.9801\n",
            "Step 5500: Train Loss: 0.0624 | Train Acc: 0.9798\n",
            "Step 5600: Train Loss: 0.0644 | Train Acc: 0.9794\n",
            "Step 5700: Train Loss: 0.0660 | Train Acc: 0.9788\n",
            "Step 5800: Train Loss: 0.0662 | Train Acc: 0.9787\n",
            "Step 5900: Train Loss: 0.0662 | Train Acc: 0.9787\n",
            "Step 6000: Train Loss: 0.0655 | Train Acc: 0.9790\n",
            "Step 6100: Train Loss: 0.0658 | Train Acc: 0.9789\n",
            "Step 6200: Train Loss: 0.0663 | Train Acc: 0.9787\n",
            "Epoch 4 Summary\n",
            "Train Loss: 0.0669 | Train Acc: 0.9784\n",
            "Val Loss: 0.1566 | Val Acc: 0.9506\n",
            "------------------------------\n",
            "Epoch 5/10\n",
            "------------------------------\n",
            "Step 6300: Train Loss: 0.0515 | Train Acc: 0.9837\n",
            "Step 6400: Train Loss: 0.0444 | Train Acc: 0.9842\n",
            "Step 6500: Train Loss: 0.0444 | Train Acc: 0.9848\n",
            "Step 6600: Train Loss: 0.0449 | Train Acc: 0.9847\n",
            "Step 6700: Train Loss: 0.0481 | Train Acc: 0.9834\n",
            "Step 6800: Train Loss: 0.0506 | Train Acc: 0.9828\n",
            "Step 6900: Train Loss: 0.0510 | Train Acc: 0.9829\n",
            "Step 7000: Train Loss: 0.0532 | Train Acc: 0.9821\n",
            "Step 7100: Train Loss: 0.0542 | Train Acc: 0.9818\n",
            "Step 7200: Train Loss: 0.0540 | Train Acc: 0.9818\n",
            "Step 7300: Train Loss: 0.0541 | Train Acc: 0.9819\n",
            "Step 7400: Train Loss: 0.0543 | Train Acc: 0.9817\n",
            "Step 7500: Train Loss: 0.0539 | Train Acc: 0.9818\n",
            "Step 7600: Train Loss: 0.0549 | Train Acc: 0.9814\n",
            "Step 7700: Train Loss: 0.0554 | Train Acc: 0.9813\n",
            "Step 7800: Train Loss: 0.0560 | Train Acc: 0.9812\n",
            "Epoch 5 Summary\n",
            "Train Loss: 0.0561 | Train Acc: 0.9811\n",
            "Val Loss: 0.1438 | Val Acc: 0.9560\n",
            "------------------------------\n",
            "Epoch 6/10\n",
            "------------------------------\n",
            "Step 7900: Train Loss: 0.0473 | Train Acc: 0.9853\n",
            "Step 8000: Train Loss: 0.0419 | Train Acc: 0.9867\n",
            "Step 8100: Train Loss: 0.0398 | Train Acc: 0.9875\n",
            "Step 8200: Train Loss: 0.0384 | Train Acc: 0.9882\n",
            "Step 8300: Train Loss: 0.0407 | Train Acc: 0.9871\n",
            "Step 8400: Train Loss: 0.0422 | Train Acc: 0.9864\n",
            "Step 8500: Train Loss: 0.0422 | Train Acc: 0.9863\n",
            "Step 8600: Train Loss: 0.0426 | Train Acc: 0.9860\n",
            "Step 8700: Train Loss: 0.0416 | Train Acc: 0.9865\n",
            "Step 8800: Train Loss: 0.0415 | Train Acc: 0.9864\n",
            "Step 8900: Train Loss: 0.0423 | Train Acc: 0.9859\n",
            "Step 9000: Train Loss: 0.0434 | Train Acc: 0.9856\n",
            "Step 9100: Train Loss: 0.0439 | Train Acc: 0.9853\n",
            "Step 9200: Train Loss: 0.0442 | Train Acc: 0.9852\n",
            "Step 9300: Train Loss: 0.0449 | Train Acc: 0.9850\n",
            "Epoch 6 Summary\n",
            "Train Loss: 0.0451 | Train Acc: 0.9850\n",
            "Val Loss: 0.1594 | Val Acc: 0.9517\n",
            "------------------------------\n",
            "Epoch 7/10\n",
            "------------------------------\n",
            "Step 9400: Train Loss: 0.0318 | Train Acc: 0.9929\n",
            "Step 9500: Train Loss: 0.0321 | Train Acc: 0.9910\n",
            "Step 9600: Train Loss: 0.0340 | Train Acc: 0.9894\n",
            "Step 9700: Train Loss: 0.0353 | Train Acc: 0.9887\n",
            "Step 9800: Train Loss: 0.0332 | Train Acc: 0.9890\n",
            "Step 9900: Train Loss: 0.0351 | Train Acc: 0.9883\n",
            "Step 10000: Train Loss: 0.0368 | Train Acc: 0.9878\n",
            "Step 10100: Train Loss: 0.0388 | Train Acc: 0.9871\n",
            "Step 10200: Train Loss: 0.0383 | Train Acc: 0.9870\n",
            "Step 10300: Train Loss: 0.0386 | Train Acc: 0.9869\n",
            "Step 10400: Train Loss: 0.0385 | Train Acc: 0.9869\n",
            "Step 10500: Train Loss: 0.0388 | Train Acc: 0.9868\n",
            "Step 10600: Train Loss: 0.0388 | Train Acc: 0.9867\n",
            "Step 10700: Train Loss: 0.0399 | Train Acc: 0.9862\n",
            "Step 10800: Train Loss: 0.0406 | Train Acc: 0.9859\n",
            "Step 10900: Train Loss: 0.0414 | Train Acc: 0.9857\n",
            "Epoch 7 Summary\n",
            "Train Loss: 0.0417 | Train Acc: 0.9856\n",
            "Val Loss: 0.1361 | Val Acc: 0.9592\n",
            "------------------------------\n",
            "Epoch 8/10\n",
            "------------------------------\n",
            "Step 11000: Train Loss: 0.0323 | Train Acc: 0.9873\n",
            "Step 11100: Train Loss: 0.0314 | Train Acc: 0.9890\n",
            "Step 11200: Train Loss: 0.0289 | Train Acc: 0.9900\n",
            "Step 11300: Train Loss: 0.0282 | Train Acc: 0.9901\n",
            "Step 11400: Train Loss: 0.0290 | Train Acc: 0.9901\n",
            "Step 11500: Train Loss: 0.0293 | Train Acc: 0.9900\n",
            "Step 11600: Train Loss: 0.0303 | Train Acc: 0.9894\n",
            "Step 11700: Train Loss: 0.0317 | Train Acc: 0.9890\n",
            "Step 11800: Train Loss: 0.0309 | Train Acc: 0.9894\n",
            "Step 11900: Train Loss: 0.0303 | Train Acc: 0.9896\n",
            "Step 12000: Train Loss: 0.0313 | Train Acc: 0.9894\n",
            "Step 12100: Train Loss: 0.0331 | Train Acc: 0.9886\n",
            "Step 12200: Train Loss: 0.0343 | Train Acc: 0.9884\n",
            "Step 12300: Train Loss: 0.0347 | Train Acc: 0.9882\n",
            "Step 12400: Train Loss: 0.0356 | Train Acc: 0.9878\n",
            "Step 12500: Train Loss: 0.0358 | Train Acc: 0.9876\n",
            "Epoch 8 Summary\n",
            "Train Loss: 0.0357 | Train Acc: 0.9877\n",
            "Val Loss: 0.1479 | Val Acc: 0.9560\n",
            "------------------------------\n",
            "Epoch 9/10\n",
            "------------------------------\n",
            "Step 12600: Train Loss: 0.0249 | Train Acc: 0.9906\n",
            "Step 12700: Train Loss: 0.0290 | Train Acc: 0.9900\n",
            "Step 12800: Train Loss: 0.0292 | Train Acc: 0.9900\n",
            "Step 12900: Train Loss: 0.0285 | Train Acc: 0.9901\n",
            "Step 13000: Train Loss: 0.0281 | Train Acc: 0.9904\n",
            "Step 13100: Train Loss: 0.0279 | Train Acc: 0.9904\n",
            "Step 13200: Train Loss: 0.0275 | Train Acc: 0.9908\n",
            "Step 13300: Train Loss: 0.0281 | Train Acc: 0.9907\n",
            "Step 13400: Train Loss: 0.0295 | Train Acc: 0.9903\n",
            "Step 13500: Train Loss: 0.0308 | Train Acc: 0.9899\n",
            "Step 13600: Train Loss: 0.0314 | Train Acc: 0.9896\n",
            "Step 13700: Train Loss: 0.0315 | Train Acc: 0.9895\n",
            "Step 13800: Train Loss: 0.0327 | Train Acc: 0.9890\n",
            "Step 13900: Train Loss: 0.0334 | Train Acc: 0.9889\n",
            "Step 14000: Train Loss: 0.0342 | Train Acc: 0.9886\n",
            "Epoch 9 Summary\n",
            "Train Loss: 0.0346 | Train Acc: 0.9885\n",
            "Val Loss: 0.1419 | Val Acc: 0.9593\n",
            "------------------------------\n",
            "Epoch 10/10\n",
            "------------------------------\n",
            "Step 14100: Train Loss: 0.0231 | Train Acc: 0.9924\n",
            "Step 14200: Train Loss: 0.0253 | Train Acc: 0.9915\n",
            "Step 14300: Train Loss: 0.0302 | Train Acc: 0.9887\n",
            "Step 14400: Train Loss: 0.0292 | Train Acc: 0.9896\n",
            "Step 14500: Train Loss: 0.0278 | Train Acc: 0.9901\n",
            "Step 14600: Train Loss: 0.0286 | Train Acc: 0.9902\n",
            "Step 14700: Train Loss: 0.0287 | Train Acc: 0.9901\n",
            "Step 14800: Train Loss: 0.0289 | Train Acc: 0.9901\n",
            "Step 14900: Train Loss: 0.0291 | Train Acc: 0.9899\n",
            "Step 15000: Train Loss: 0.0295 | Train Acc: 0.9898\n",
            "Step 15100: Train Loss: 0.0299 | Train Acc: 0.9897\n",
            "Step 15200: Train Loss: 0.0300 | Train Acc: 0.9895\n",
            "Step 15300: Train Loss: 0.0305 | Train Acc: 0.9893\n",
            "Step 15400: Train Loss: 0.0304 | Train Acc: 0.9894\n",
            "Step 15500: Train Loss: 0.0304 | Train Acc: 0.9896\n",
            "Step 15600: Train Loss: 0.0302 | Train Acc: 0.9897\n",
            "Epoch 10 Summary\n",
            "Train Loss: 0.0306 | Train Acc: 0.9895\n",
            "Val Loss: 0.1402 | Val Acc: 0.9579\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R2BK-jn60TSC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}