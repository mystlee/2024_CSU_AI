{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjrsDO5nqeFwKl4GCnPZWk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mystlee/2024_CSU_AI_class/blob/main/HW_chapter3_decision_tree_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**scikit-learn**을 사용하지 말고 직접 구현해보자!"
      ],
      "metadata": {
        "id": "nXnXHDnXzpg6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bwb8OomtzggR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = {'Outlook':     ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain',\n",
        "                        'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain',\n",
        "                        'Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
        "        'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool',\n",
        "                        'Cool', 'Cool', 'Mild', 'Cool', 'Mild',\n",
        "                        'Mild', 'Mild', 'Hot', 'Mild'],\n",
        "        'Humidity':    ['High', 'High', 'High', 'High', 'Normal',\n",
        "                        'Normal', 'Normal', 'High', 'Normal', 'Normal',\n",
        "                        'Normal', 'High', 'Normal', 'High'],\n",
        "        'Wind':        ['Weak', 'Strong', 'Weak', 'Weak', 'Weak',\n",
        "                        'Strong', 'Strong', 'Weak', 'Weak', 'Weak',\n",
        "                        'Strong', 'Strong', 'Weak', 'Strong'],\n",
        "\n",
        "        'PlayTennis':  ['No', 'No', 'Yes', 'Yes', 'Yes',\n",
        "                        'No', 'Yes', 'No', 'Yes', 'Yes',\n",
        "                        'Yes', 'Yes', 'Yes', 'No']}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "def entropy(target_col):\n",
        "    elements, counts = np.unique(target_col, return_counts = True)\n",
        "    entropy = 0\n",
        "    # WRITE YOUT CODE\n",
        "    # FROM HERE\n",
        "    # hint: elements에 대해 반복문을 통해 각 class에 대해\n",
        "    #       entopry를 계산하고 합산\n",
        "    # END\n",
        "    return entropy\n",
        "\n",
        "def information_gain(data, split_attribute_name, target_name = \"PlayTennis\"):\n",
        "    total_entropy = entropy(data[target_name])\n",
        "\n",
        "    # 해당 속성으로 데이터를 분할한 후, 각 분할의 엔트로피와 가중치를 계산\n",
        "    vals, counts = np.unique(data[split_attribute_name], return_counts=True)\n",
        "    weighted_entropy = 0.\n",
        "    # WRITE YOUT CODE\n",
        "    # FROM HERE\n",
        "    # 각 class에 따른 entropy를 계산하고, 가중치를 계산\n",
        "    # hint: vals에 대해 반복문을 통해 각 class에 대한 entopry를 구하고\n",
        "    #       entropy를 count로 나눈 다음에 전체 entropy를 계산\n",
        "    # END\n",
        "\n",
        "    # information gain 계산\n",
        "    information_gain = total_entropy - weighted_entropy\n",
        "    return information_gain\n",
        "\n",
        "def choose_parent_node_class(data, target_name = \"PlayTennis\"):\n",
        "    classes, counts = np.unique(data[target_name], return_counts=True)\n",
        "    entropies = []\n",
        "\n",
        "    for i in range(len(classes)):\n",
        "        subset = data[data[target_name] == classes[i]]\n",
        "        entropies.append(entropy(subset[target_name]))\n",
        "\n",
        "    # entropy가 가장 낮은 class를 선택 (= IG가 가장 높은 class 선택)\n",
        "    return classes[np.argmin(entropies)]\n",
        "\n",
        "def decision_tree(data, original_data, features, target_name = \"PlayTennis\", parent_node_class = None):\n",
        "    # 종료 조건 1: 모든 샘플이 같은 class에 속하는 경우\n",
        "    if len(np.unique(data[target_name])) == 1:\n",
        "        return np.unique(data[target_name])[0]\n",
        "\n",
        "    # 종료 조건 2: 데이터가 비어있는 경우\n",
        "    elif len(data) == 0:\n",
        "        return np.unique(original_data[target_name])[np.argmax(np.unique(original_data[target_name], return_counts = True)[1])]\n",
        "\n",
        "    # 종료 조건 3: 사용할 attribution이 더 이상 없는 경우\n",
        "    elif len(features) == 0:\n",
        "        return parent_node_class\n",
        "\n",
        "    # 그 외의 경우에는 main 및 sub 트리 구축 진행\n",
        "    else:\n",
        "        # # 초기 설정\n",
        "        # 1. IG가 가장 높은 class를 부모 node로 선택\n",
        "        parent_node_class = choose_parent_node_class(original_data, target_name)\n",
        "        # 2. 부모 node의 class를 가장 빈도가 높은 값으로 설정\n",
        "        # parent_node_class = np.unique(data[target_name])[np.argmax(np.unique(data[target_name], return_counts = True)[1])]\n",
        "\n",
        "        # IG가 가장 큰 attr.를 선택\n",
        "        item_values = [information_gain(data, feature, target_name) for feature in features]\n",
        "        best_feature_index = np.argmax(item_values)\n",
        "        best_feature = features[best_feature_index]\n",
        "\n",
        "        # decision tree 생성\n",
        "        tree = {best_feature: {}}\n",
        "\n",
        "        # 선택된 특징을 제외한 리스트 생성\n",
        "        features = [i for i in features if i != best_feature]\n",
        "\n",
        "        # 각 분할에 대해 recursive하게 tree를 생성\n",
        "        for value in np.unique(data[best_feature]):\n",
        "            sub_data = data[data[best_feature] == value]\n",
        "            subtree = decision_tree(sub_data, original_data, features, target_name, parent_node_class)\n",
        "            tree[best_feature][value] = subtree\n",
        "\n",
        "        return tree\n",
        "\n",
        "# Entropy를 이용한 decision tree 생성\n",
        "tree = decision_tree(df, df, df.columns[:-1])\n",
        "print(tree)\n"
      ]
    }
  ]
}